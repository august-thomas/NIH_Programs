{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF is a measure of how much the variance of the coefficient derived from the model is inflated by collinearity. It helps detect multicollinearity that you cannot catch just by eyeballing a pairwise correlation plot and even detects strong relations between 3 variables and more.\n",
    "\n",
    "It is calculated by taking the ratio of **the variance of all of the coefficients** divided by **the variance of that one variable’s coefficient when it is the only variable in the model**.\n",
    "- VIF = 1 : No correlation between that predictor and the other variables\n",
    "- VIF = 4 : Suspicious, needs to be looked into\n",
    "- VIF = 5-10 : Look into it or drop the variable.\n",
    "\n",
    "Why is multicollinearity an issue with regression? Well, the regression equation is the best fit line to represent the effects of your predictors and the dependant variable, and does not include the effects of one predictor on another.\n",
    "Having high collinearity (correlation of 1.00) between predictors will affect your coefficients and the accuracy, plus its ability to reduce the SSE (sum of squared errors — that thing you need to minimise with your regression).\n",
    "\n",
    "While variables in a dataset are usually correlated to a small degree, highly collinear variables can be redundant in the sense that we only need to retain one of the features to give our model the necessary information.\n",
    "Removing collinear features is a method to reduce model complexity by decreasing the number of features and can help to increase model generalization. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as smapi\n",
    "import os\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VIF_tester:\n",
    "    \n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    This class is called on large .dataforML files to quickly evaluate a \n",
    "    'quick and dirty' estimate of the variance inflation factor between predictors.\n",
    "    It's output is a cleaned up and reconstituted .dataforML file.\n",
    "    \n",
    "    ATTRIBUTES:\n",
    "    1):filepaths: --> List of filepaths corresponding to your data. \n",
    "    Every VIF_tester object and method should know which files are undergoing analysis.\n",
    "    2):\n",
    "    \n",
    "    CONSTRUCTOR VARIABLES:\n",
    "    1):X: --> .dataforML file (an error is raised if other file types are passed).\n",
    "    2):threshold: --> VIF threshold (defaults to 5.0).\n",
    "    \n",
    "    METHODS:\n",
    "    1): dt_chk(X) --> Responsible for evaluating whether passed file is appropriate for VIF analysis, \n",
    "    and separates it into testable pieces. Currently does not separate the file via bootleg-stype procedure, \n",
    "    but this may change depending on kernel memory availability. More detail below.\n",
    "    2): vif_chk(X, threshold) --> Conducts VIF comparison on list of DataFrames returned by dt_chk(). More detail below.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, threshold=5.0):\n",
    "        self.X = X\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def dt_chk(filepaths):\n",
    "        \n",
    "        \"\"\"\n",
    "        FUNCTION:\n",
    "        This method reads in a file, determines whether the file is of the .mydataML type, drops any non-numeric columns and \n",
    "        ensures that remaining data is numerical, and then parses through the resulting DataFrame in order to split it into\n",
    "        so-called \"chunks.\" It returns a list of \"chunked\" DataFrame objects.\n",
    "        \n",
    "        Currently, this method arbitrarily picks a number of SNP covariates to chunk by, but could be extended to chuck\n",
    "        based on the number of available cores for a job sent to an HPC center.\n",
    "\n",
    "        INPUTS :\n",
    "        :X: --> Any .mydataML file large enough to warrant evaluation in chunks.\n",
    "\n",
    "        RETURNS\n",
    "        :df_snp_list: --> A list including a series of DataFrame objects.\n",
    "        \"\"\"\n",
    "\n",
    "        for X in filepaths:\n",
    "            # Split the extension from the path and normalise it to lowercase.\n",
    "            ext = os.path.splitext(X)[-1].lower()\n",
    "            # Now we can simply use == to check for equality, no need for wildcards.\n",
    "            if ext == \".dataforml\":\n",
    "                \n",
    "                print(\"\"\"\n",
    "                      This is a dataForML file! \n",
    "                      Checking data for proper types ...\n",
    "                      \"\"\")\n",
    "                df = pd.read_csv(X, sep=\"\\t\")\n",
    "                df.columns = df.columns.str.strip() # Strip erroneous white space.\n",
    "                df.dropna()\n",
    "                df = df._get_numeric_data() #drop non-numeric cols\n",
    "                \n",
    "                # Ensure that data is of an appropriate type:\n",
    "                data_type = df.dtypes\n",
    "                int_cols = \\\n",
    "                df.select_dtypes(include=[\"int\", \"int16\", \"int32\", \"int64\", \"float\", \n",
    "                                         \"float16\", \"float32\", \"float64\"]).shape[1]\n",
    "                total_cols = df.shape[1]\n",
    "                try:\n",
    "                    if int_cols != total_cols:\n",
    "                        raise Value_Error(\"All columns in the input need to be numerical for a multicollinearity test.\")\n",
    "                    else:\n",
    "                        print(\"\"\"\n",
    "                                This dataframe is acceptable for multicollinearity VIF analysis. \n",
    "                                Proceeding to dataframe conversion & fragmentation phase ...\n",
    "                                \"\"\")\n",
    "                        \n",
    "                except ValueError as error:\n",
    "                    print(\"Error: \", error)\n",
    "                    \n",
    "                df_snp_list = []\n",
    "                cov_uni = df.iloc[:,1:5]\n",
    "                pheno_df = df.iloc[:,0:1]\n",
    "                cov_snps = df.iloc[:,5:]\n",
    "                snp_count = len(cov_snps)\n",
    "                snp_counter = 0\n",
    "                chunk_delim = 50\n",
    "                num_chunks = 1\n",
    "                eof = False\n",
    "                    \n",
    "                # This loop will iterate through the snp_count DataFrame to split it into chunks.\n",
    "                # chunk_delim will determine the size of the DataFrames passed to vif_multicollinearity_check()\n",
    "                \n",
    "                while eof == False:\n",
    "                    if chunk_delim >= snp_count:\n",
    "                        df_snp_list.append(cov_snps.iloc[:,snp_counter:])\n",
    "                        print('\\n'\n",
    "                                'SNP elements added to chunk #', num_chunks,\n",
    "                                'range from', snp_counter, \n",
    "                                'to the end of the input file at position',snp_count\n",
    "                             )                         \n",
    "                        print('\\n'\n",
    "                            'Chunked DataFrame #', num_chunks,\n",
    "                            'has been added to the list and is ready to be passed to VIF calculator!'\n",
    "                             )\n",
    "                        eof == True\n",
    "                        return df_snp_list\n",
    "                        break\n",
    "                    else:\n",
    "                        df_snp_list.append(cov_snps.iloc[:,snp_counter:chunk_delim])\n",
    "                        print('\\n'\n",
    "                                'SNP elements added to chunk #', num_chunks,\n",
    "                                'range from', snp_counter, \n",
    "                                'to', chunk_delim\n",
    "                             )\n",
    "                        print('\\n'\n",
    "                            'Chunked DataFrame #', num_chunks,\n",
    "                            'has been added to the list and is ready to be passed to VIF calculator!'\n",
    "                             )\n",
    "                        num_chunks += 1\n",
    "                        snp_counter = chunk_delim\n",
    "                        chunk_delim += 50\n",
    "\n",
    "                \n",
    "        # BUG: I can't figure out why these other columns won't append \n",
    "        # onto each DataFrame in the final list.\n",
    "                \n",
    "                    #for df in df_snp_list:\n",
    "                     #   df.append(cov_uni.iloc[:,0:])\n",
    "                return df_snp_list, cov_uni;\n",
    "               \n",
    "            else:\n",
    "                print(\"this is an invalid file format. Aborting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def vif_check(chunked_list, theshold=5.0):\n",
    "        \n",
    "        \"\"\"\n",
    "        FUNCTION\n",
    "        Checks for multicollinearity between features in a given chunk of the original DataFrame and \n",
    "        removes features with a VIF greater than a specifed threshold. Recombines surviving features,\n",
    "        calls .dt_chk to rechuck them, then recursively calls itself on .dt_chk's output until\n",
    "        no multicollinearity in any tested chunk is found.\n",
    "\n",
    "        INPUTS \n",
    "        :chunked_list: --> A list of chunked DataFrame objects built by .dt_chk\n",
    "        :threshold: --> The collinearity threshold at which elements are removed (DEFAULT = 5.0)\n",
    "\n",
    "        RETURNS\n",
    "        --> A DataFrame with as many non-multicolinear elements from the original infile as possible.\n",
    "        \"\"\"\n",
    "        pruned_df = []\n",
    "        \n",
    "        for chunk in chunked_list:\n",
    "            \n",
    "            # Create a list of indices corresponding to each column in a given chunk.\n",
    "            variables = list(range(chunk.shape[1]))\n",
    "            print(variables)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5ee027e90f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvif_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt_chk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "    test_obj = self.vif_check(self.dt_chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "            dropped = True\n",
    "                \n",
    "            print(\"\"\"\n",
    "            \\n\n",
    "            The VIF calculation will now iterate through the features of each chunk and calculate \n",
    "            their respective values. VIF is calculated by taking the ratio of the variance of all of the coefficients \n",
    "            divided by the variance of that one variable’s coefficient when it is the only variable in the model.\n",
    "            This function shall drop all features exceeding the specified threshold, and combine the remaining\n",
    "            features into a new DataFrame object.\n",
    "            \\n\n",
    "                \"\"\")\n",
    "                \n",
    "            while dropped:\n",
    "                dropped = False\n",
    "                vif = [variance_inflation_factor(X.iloc[:, variables].values, var) for var in variables]\n",
    "                #print(\"\\n\\n The VIF is: \", vif)\n",
    "                max_loc = vif.index(max(vif))\n",
    "                \n",
    "                if max(vif) > threshold:\n",
    "                    print(\"Dropping \\\"\" + X.iloc[:, variables].columns[max_loc] + \"\\\" at index: \" + str(max_loc))\n",
    "                    X.drop(X.columns[variables[max_loc]], 1, inplace=True)\n",
    "                    variables = list(range(X.shape[1]))\n",
    "                    dropped = True\n",
    "                    \n",
    "                else:\n",
    "                    pruned_dataframes.append(X)\n",
    "                \n",
    "            return pruned_dataframes\n",
    "        \n",
    "        X = VIF_tester.dt_chk('discrete.DATAFORML')\n",
    "        vif_df_list = VIF_tester.vif_check(X)\n",
    "        for element in vif_df_list:\n",
    "            print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
